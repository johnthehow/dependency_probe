[CORRELATION INDICES]
Spearman	0.8900871710928824
Pearson	0.8177088377410893

[UUAS]
UUAS	0.5145778114350624

[PROBE SETTINGS]
MODEL_PATH	D:\transformers\bert\bert_large_uncased
MODEL_NAME	bert_large_uncased
NDIM_TOKEN_EMBEDDING	1024
ONSITE_EMBEDDINGS	False
ONSITE_PROBES	True
LEARNING_RATE	0.001
PROBE_RANK	64
PROBE_CUDA	False
BATCH_SIZE	100
DEPD_DIRECTED	False
CONLL_PATH	C:\Program Files\Python37\Lib\site-packages\thehow\dependency_probe\datasets\conll\gum
TRAIN_CONLL_PATH	C:\Program Files\Python37\Lib\site-packages\thehow\dependency_probe\datasets\conll\gum\en_gum-ud-train.conllu
DEV_CONLL_PATH	C:\Program Files\Python37\Lib\site-packages\thehow\dependency_probe\datasets\conll\gum\en_gum-ud-dev.conllu
TEST_CONLL_PATH	C:\Program Files\Python37\Lib\site-packages\thehow\dependency_probe\datasets\conll\gum\en_gum-ud-test.conllu
DATASET_PKL_PATH	C:\Program Files\Python37\Lib\site-packages\thehow\dependency_probe\datasets\pkl
PROBE_SAVEPATH	C:\Program Files\Python37\Lib\site-packages\thehow\dependency_probe\probes
EPOCHS	20
REPORTS_PATH	C:\Program Files\Python37\Lib\site-packages\thehow\dependency_probe\reports

[PROBE ARCHIVE]
probe_bert_large_uncased_ndim_1024_rank_64_layer_12_directed_False.pth

[TRAINING LOSSES]
0	[8.301225735591007, 5.215553134679794]
1	[4.139875998863807, 4.031389236450195]
2	[3.487494785052079, 3.741283357143402]
3	[3.2727056856338796, 3.61520816385746]
4	[3.1658500799765954, 3.5597449392080307]
5	[3.102946428152231, 3.511876568198204]
6	[3.0673167545061846, 3.515102133154869]
7	[3.0455198677686544, 3.4951770305633545]
8	[3.024469384780297, 3.489972934126854]
9	[3.0038548409938812, 3.4727897197008133]
10	[2.9948935279479394, 3.4867826998233795]
11	[2.9874271269028005, 3.4679296612739563]
12	[2.988515099653831, 3.4659987539052963]
13	[2.9836744299301734, 3.4797656685113907]
14	[2.9787977383686948, 3.4863988161087036]
15	[2.971366912126541, 3.4852553009986877]
16	[2.970923907481707, 3.469460666179657]
17	[2.968654657785709, 3.473970577120781]
18	[2.9629720678696265, 3.470513805747032]
19	[2.9603179899545817, 3.4662792682647705]
